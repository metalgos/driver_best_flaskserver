{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c36a3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 26, 34, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 26, 34, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 17, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 17, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 8, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1536)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               786944    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 880,129\n",
      "Trainable params: 880,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import cv2, dlib  # 이미지 표현 및 눈 좌표 얻어오기\n",
    "import numpy as np  # 데이터 처리\n",
    "from imutils import face_utils  # 얼굴 분석\n",
    "from tensorflow import keras  # 모델 학습 및 테스트\n",
    "from playsound import playsound  # 소리 재생\n",
    "import threading  # 스레드 사용\n",
    "\n",
    "# 추출할 눈 이미지 사이즈\n",
    "IMG_SIZE = (34, 26)\n",
    "# 눈을 감은 프레임을 세줄 변수\n",
    "n_count = 0\n",
    "# 경보음 다중재생 방지 변수\n",
    "global is_playing\n",
    "is_playing = False\n",
    "\n",
    "# 얼굴에 68개의 점을 찍음 \n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "# 학습한 모델을 불러옴\n",
    "model = keras.models.load_model('models/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "# 눈을 찾아주는 함수\n",
    "def crop_eye(img, eye_points):\n",
    "    x1, y1 = np.amin(eye_points, axis=0)\n",
    "    x2, y2 = np.amax(eye_points, axis=0)\n",
    "    cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "    w = (x2 - x1) * 1.2\n",
    "    h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "    margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "    min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "    max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "    eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "    eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "    return eye_img, eye_rect\n",
    "\n",
    "\n",
    "def playSound():\n",
    "    global is_playing\n",
    "    t = threading.Thread(target=thread)\n",
    "    # 스레드를 시작한후 join해서 동작이 멈추길 기다린 후 is_plaing을 false로 바꿔 소리 재생이 가능하도록.\n",
    "    t.start()\n",
    "    t.join()\n",
    "    is_playing = False\n",
    "\n",
    "\n",
    "def thread():\n",
    "    playsound(\"sound.wav\")\n",
    "\n",
    "\n",
    "# main\n",
    "#cap = cv2.VideoCapture('videos/5.mp4')\n",
    "cap = cv2.VideoCapture('C:\\\\eGovFrame-3.10.0\\\\bin\\\\eclipse\\\\checkupload\\\\membervid\\\\2\\\\vid_2022_12_05_09_28_10.mp4')\n",
    "\n",
    "#cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, img_ori = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "    img = img_ori.copy()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray)\n",
    "\n",
    "    for face in faces:\n",
    "        shapes = predictor(gray, face)\n",
    "        shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "        eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "        eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "        eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "        eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "        eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "        # cv2.imshow('l', eye_img_l)\n",
    "        # cv2.imshow('r', eye_img_r)\n",
    "\n",
    "        eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "        eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "        pred_l = model.predict(eye_input_l)\n",
    "        pred_r = model.predict(eye_input_r)\n",
    "\n",
    "        if pred_l < 0.1 and pred_r < 0.1:\n",
    "            n_count += 1\n",
    "        else:\n",
    "            n_count = 0\n",
    "            is_playing = False\n",
    "            # playsound(\"\")\n",
    "\n",
    "        if n_count > 100:\n",
    "            cv2.putText(img, \"Wake up\", (120, 160), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "            # 스레드에서 사운드 재생\n",
    "            if not is_playing:\n",
    "                is_playing = True\n",
    "                t = threading.Thread(target=playSound)\n",
    "                t.start()\n",
    "\n",
    "        # visualize\n",
    "        state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "        state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "        state_l = state_l % pred_l\n",
    "        state_r = state_r % pred_r\n",
    "\n",
    "        # 색 지정\n",
    "        if pred_l > 0.1:\n",
    "            l_color = (255, 255, 255)\n",
    "        else:\n",
    "            l_color = (0, 0, 255)\n",
    "        if pred_r > 0.1:\n",
    "            r_color = (255, 255, 255)\n",
    "        else:\n",
    "            r_color = (0, 0, 255)\n",
    "\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(l_color), thickness=2)\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(r_color), thickness=2)\n",
    "\n",
    "        cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (l_color), 2)\n",
    "        cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (r_color), 2)\n",
    "\n",
    "    # 크기 조절\n",
    "    img = cv2.resize(img, dsize=(480, 320), interpolation=cv2.INTER_LINEAR)\n",
    "    cv2.imshow('result', img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d06d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def gotojsp2():\n",
    "    URL = \"http://localhost:8085/controller/flask/upsleepy?deepresult=\"+file_path\n",
    "    response = requests.get(URL)\n",
    "    \n",
    "file_path = \"22\"\n",
    "\n",
    "gotojsp2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37153f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [06/Dec/2022 11:37:46] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [06/Dec/2022 11:37:50] \"GET /gotojsp3 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Dec/2022 11:37:57] \"GET /gotojsp3 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Dec/2022 11:37:57] \"GET /gotojsp3 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Dec/2022 11:37:59] \"GET /gotojsp3 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Dec/2022 11:37:59] \"GET /gotojsp3 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Dec/2022 11:37:59] \"GET /gotojsp3 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Dec/2022 11:38:14] \"GET /gotojsp3 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Dec/2022 11:38:14] \"GET /gotojsp3 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Dec/2022 11:38:14] \"GET /gotojsp3 HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "#플라스크 실행\n",
    "from flask import Flask #간단히 플라스크 서버를 만든다\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "from flask import Flask\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "import requests\n",
    "    \n",
    "@app.route(\"/gotojsp3\")\n",
    "def gotojsp3():\n",
    "    URL = \"http://localhost:8085/controller/flask/upsleepy?deepresult=23\"\n",
    "    response = requests.get(URL)\n",
    " \n",
    "    return 'gotojsp3'\n",
    "\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False,host=\"127.0.0.1\",port=5000)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5026288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "\n",
    "URL = \"http://localhost:8085/controller/flask/upsleepy?deepresult=딥런이결과\"\n",
    "response = requests.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2181627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경 셋팅\n",
    "import h5py\n",
    "# import necessary packages\n",
    "import cvlib as cv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "\n",
    "import cv2, dlib  # 이미지 표현 및 눈 좌표 얻어오기\n",
    "import numpy as np  # 데이터 처리\n",
    "from imutils import face_utils  # 얼굴 분석\n",
    "from tensorflow import keras  # 모델 학습 및 테스트\n",
    "from playsound import playsound  # 소리 재생\n",
    "import threading  # 스레드 사용\n",
    "\n",
    "\n",
    "#도난방지\n",
    "car_500 = load_model('theaf_modelh5/car_500.h5')\n",
    "car_500.summary()\n",
    "\n",
    "\n",
    "import os # 파일 마지막꺼 출력\n",
    "import asyncio#비동기 함수 사용\n",
    "import requests#통신 관련\n",
    "\n",
    "\n",
    "#파일 업로드 처리,플라스크 관련\n",
    "from flask import Flask, render_template, request, redirect, url_for\n",
    "from flaskext.mysql import MySQL\n",
    "from werkzeug.utils import secure_filename\n",
    "import urllib.request\n",
    "\n",
    "# 추출할 눈 이미지 사이즈\n",
    "IMG_SIZE = (34, 26)\n",
    "# 눈을 감은 프레임을 세줄 변수\n",
    "#n_count = 0\n",
    "# 경보음 다중재생 방지 변수\n",
    "global is_playing\n",
    "is_playing = False\n",
    "\n",
    "\n",
    "n_count=0 #도난방지 확인 프레임 버퍼\n",
    "    \n",
    "\n",
    "# open webcam\n",
    "webcam = cv2.VideoCapture('checkc_upload_vid_thef/65/test_vid.mp4')\n",
    "\n",
    "new_count = 0\n",
    "new_fps=1\n",
    "\n",
    "\n",
    "# loop through frames\n",
    "while webcam.isOpened():\n",
    "\n",
    "    new_count+=1\n",
    "    # read frame from webcam \n",
    "    status, frame = webcam.read()\n",
    "\n",
    "    if not status:\n",
    "        print(\"Could not read frame\")\n",
    "        exit()\n",
    "\n",
    "    if(new_count%new_fps==0): \n",
    "\n",
    "        # apply face detection\n",
    "        face, confidence = cv.detect_face(frame)\n",
    "\n",
    "        # loop through detected faces\n",
    "        for idx, f in enumerate(face):\n",
    "\n",
    "            (startX, startY) = f[0], f[1]\n",
    "            (endX, endY) = f[2], f[3]\n",
    "\n",
    "            if 0 <= startX <= frame.shape[1] and 0 <= endX <= frame.shape[1] and 0 <= startY <= frame.shape[0] and 0 <= endY <= frame.shape[0]:\n",
    "\n",
    "                face_region = frame[startY:endY, startX:endX]\n",
    "\n",
    "                face_region1 = cv2.resize(face_region, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "                x = img_to_array(face_region1)\n",
    "                x = np.expand_dims(x, axis=0)\n",
    "                x = preprocess_input(x)\n",
    "\n",
    "                prediction = car_500.predict(x)\n",
    "\n",
    "                if prediction < 0.7: # 마스크 미착용으로 판별되면, \n",
    "                    cv2.rectangle(frame, (startX,startY), (endX,endY), (0,255,0), 2)\n",
    "                    Y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "                    text = \"driver {:.2f}\".format((1 - prediction[0][0]))\n",
    "                    cv2.putText(frame, text, (startX,Y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "\n",
    "                    n_count = 0\n",
    "\n",
    "                else: # 마스크 착용으로 판별되면\n",
    "\n",
    "                    n_count += 1\n",
    "\n",
    "                    cv2.rectangle(frame, (startX,startY), (endX,endY), (0,0,255), 2)\n",
    "                    Y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "                    text = \"other {:.2f}\".format(prediction[0][0])\n",
    "                    cv2.putText(frame, text, (startX,Y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "                   # gotojsp_theaf(login_no)   \n",
    "                if n_count > 5:\n",
    "                    print(\"도난\")\n",
    "                    #gotojsp_theaf(login_no)                     \n",
    "                    n_count=0\n",
    "\n",
    "        # display output\n",
    "        cv2.imshow(\"driver other classify\", frame)\n",
    "\n",
    "        # press \"Q\" to stop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # release resources\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2d6815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7154f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
